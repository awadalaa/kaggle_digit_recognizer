{
 "metadata": {
  "name": "",
  "signature": "sha256:058c17a7d08128c285967e23095f4197d2754cb1b608a279c6cea1e4f2f0b672"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# import packages\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import tensorflow as tf\n",
      "from tensorflow.python.ops import rnn, rnn_cell\n",
      "\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.cm as cm\n",
      "%matplotlib inline\n",
      "\n",
      "from subprocess import check_output"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "'''\n",
      "To classify images using a bidirectional recurrent neural network, we consider\n",
      "every image row as a sequence of pixels. Because MNIST image shape is 28*28px,\n",
      "we will then handle 28 sequences of 28 steps for every sample.\n",
      "'''\n",
      "\n",
      "# Parameters\n",
      "learning_rate = 0.001\n",
      "training_iters = 100000\n",
      "batch_size = 128\n",
      "display_step = 10\n",
      "\n",
      "# Network Parameters\n",
      "n_input = 28 # MNIST data input (img shape: 28*28)\n",
      "n_steps = 28 # timesteps\n",
      "n_hidden = 128 # hidden layer num of features\n",
      "n_classes = 10 # MNIST total classes (0-9 digits)\n",
      "image_to_display = 20\n",
      "validation_size = 128"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 21
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Import MNIST data\n",
      "dataset = pd.read_csv(\"../input/train.csv\")\n",
      "test = pd.read_csv(\"../input/test.csv\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "print('dataset({0[0]},{0[1]})'.format(dataset.shape))\n",
      "print('test({0[0]},{0[1]})'.format(test.shape))\n",
      "print (dataset.head())\n",
      "print (test.head())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "dataset(42000,785)\n",
        "test(28000,784)\n",
        "   label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
        "0      1       0       0       0       0       0       0       0       0   \n",
        "1      0       0       0       0       0       0       0       0       0   \n",
        "2      1       0       0       0       0       0       0       0       0   \n",
        "3      4       0       0       0       0       0       0       0       0   \n",
        "4      0       0       0       0       0       0       0       0       0   \n",
        "\n",
        "   pixel8  pixel9  pixel10  pixel11  pixel12  pixel13  pixel14  pixel15  \\\n",
        "0       0       0        0        0        0        0        0        0   \n",
        "1       0       0        0        0        0        0        0        0   \n",
        "2       0       0        0        0        0        0        0        0   \n",
        "3       0       0        0        0        0        0        0        0   \n",
        "4       0       0        0        0        0        0        0        0   \n",
        "\n",
        "   pixel16  pixel17  pixel18      \n",
        "0        0        0        0 ...  \n",
        "1        0        0        0 ...  \n",
        "2        0        0        0 ...  \n",
        "3        0        0        0 ...  \n",
        "4        0        0        0 ...  \n",
        "\n",
        "[5 rows x 785 columns]\n",
        "   pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
        "0       0       0       0       0       0       0       0       0       0   \n",
        "1       0       0       0       0       0       0       0       0       0   \n",
        "2       0       0       0       0       0       0       0       0       0   \n",
        "3       0       0       0       0       0       0       0       0       0   \n",
        "4       0       0       0       0       0       0       0       0       0   \n",
        "\n",
        "   pixel9  pixel10  pixel11  pixel12  pixel13  pixel14  pixel15  pixel16  \\\n",
        "0       0        0        0        0        0        0        0        0   \n",
        "1       0        0        0        0        0        0        0        0   \n",
        "2       0        0        0        0        0        0        0        0   \n",
        "3       0        0        0        0        0        0        0        0   \n",
        "4       0        0        0        0        0        0        0        0   \n",
        "\n",
        "   pixel17  pixel18  pixel19      \n",
        "0        0        0        0 ...  \n",
        "1        0        0        0 ...  \n",
        "2        0        0        0 ...  \n",
        "3        0        0        0 ...  \n",
        "4        0        0        0 ...  \n",
        "\n",
        "[5 rows x 784 columns]\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels = dataset.iloc[:,0]\n",
      "images = dataset.iloc[:,1:].values\n",
      "images = images.astype(np.float)\n",
      "\n",
      "# convert from [0:255] => [0.0:1.0]\n",
      "images = np.multiply(images, 1.0 / 255.0)\n",
      "\n",
      "print('images({0[0]},{0[1]})'.format(images.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "images(42000,784)\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def display(img):\n",
      "    one_image = img.reshape(28, 28)\n",
      "    plt.axis('off')\n",
      "    plt.imshow(one_image, cmap=cm.binary)\n",
      "display(images[image_to_display])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "png": "iVBORw0KGgoAAAANSUhEUgAAAPwAAAD8CAYAAABTq8lnAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
       "text": [
        "<matplotlib.figure.Figure at 0x126f79dd0>"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "labels[image_to_display]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "8"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# print information about image size, label of image-to-display and number of labels\n",
      "labels_flat = dataset[[0]].values.ravel()\n",
      "print('length of one image ({0})'.format(len(labels_flat)))\n",
      "print ('label of image [{0}] => {1}'.format(image_to_display, labels_flat[image_to_display]))\n",
      "\n",
      "labels_count = np.unique(labels_flat).shape[0]\n",
      "print('number of labels => {0}'.format(labels_count))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "length of one image (42000)\n",
        "label of image [20] => 8\n",
        "number of labes => 10\n"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# convert class labels from scalars to one-hot vectors\n",
      "# 0 => [1 0 0 0 0 0 0 0 0 0]\n",
      "# 1 => [0 1 0 0 0 0 0 0 0 0]\n",
      "# ...\n",
      "# 9 => [0 0 0 0 0 0 0 0 0 1]\n",
      "\n",
      "def dense_to_one_hot(labels_dense, num_classes):\n",
      "    num_labels = labels_dense.shape[0]\n",
      "    print num_labels\n",
      "    index_offset = np.arange(num_labels) * num_classes\n",
      "    print index_offset\n",
      "    labels_one_hot = np.zeros((num_labels, num_classes))\n",
      "    print labels_one_hot\n",
      "    labels_one_hot.flat[index_offset + labels_dense.ravel()] = 1\n",
      "    return labels_one_hot\n",
      "\n",
      "labels = dense_to_one_hot(labels_flat, labels_count)\n",
      "labels = labels.astype(np.uint8)\n",
      "\n",
      "print('labels({0[0]},{0[1]})'.format(labels.shape))\n",
      "print ('labels vector for image [{0}] => {1}'.format(image_to_display,labels[image_to_display]))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "42000\n",
        "[     0     10     20 ..., 419970 419980 419990]\n",
        "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  0.  0.]\n",
        " ..., \n",
        " [ 0.  0.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  0.  0.]\n",
        " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
        "labels(42000,10)\n",
        "labels vector for image [20] => [0 0 0 0 0 0 0 0 1 0]\n"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# split data into training & validation sets\n",
      "validation_images = images[:validation_size]\n",
      "validation_labels = labels[:validation_size]\n",
      "\n",
      "train_images = images[validation_size:]\n",
      "train_labels = labels[validation_size:]\n",
      "train_labels_flat = labels_flat[validation_size:]\n",
      "\n",
      "\n",
      "print('train data size({0[0]},{0[1]})'.format(train_images.shape))\n",
      "print('validation data size({0[0]},{0[1]})'.format(validation_images.shape))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "train data size(41872,784)\n",
        "validation data size(128,784)\n"
       ]
      }
     ],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# tf Graph input\n",
      "x = tf.placeholder(\"float\", [None, n_steps, n_input])\n",
      "y = tf.placeholder(\"float\", [None, n_classes])\n",
      "\n",
      "# Define weights\n",
      "weights = {\n",
      "    # Hidden layer weights => 2*n_hidden because of forward + backward cells\n",
      "    'out': tf.Variable(tf.random_normal([2*n_hidden, n_classes]))\n",
      "}\n",
      "biases = {\n",
      "    'out': tf.Variable(tf.random_normal([n_classes]))\n",
      "}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def BiRNN(x, weights, biases):\n",
      "\n",
      "    # Prepare data shape to match `bidirectional_rnn` function requirements\n",
      "    # Current data input shape: (batch_size, n_steps, n_input)\n",
      "    # Required shape: 'n_steps' tensors list of shape (batch_size, n_input)\n",
      "\n",
      "    # Permuting batch_size and n_steps\n",
      "    x = tf.transpose(x, [1, 0, 2])\n",
      "    # Reshape to (n_steps*batch_size, n_input)\n",
      "    x = tf.reshape(x, [-1, n_input])\n",
      "    # Split to get a list of 'n_steps' tensors of shape (batch_size, n_input)\n",
      "    x = tf.split(0, n_steps, x)\n",
      "\n",
      "    # Define lstm cells with tensorflow\n",
      "    # Forward direction cell\n",
      "    lstm_fw_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
      "    # Backward direction cell\n",
      "    lstm_bw_cell = rnn_cell.BasicLSTMCell(n_hidden, forget_bias=1.0)\n",
      "\n",
      "    # Get lstm cell output\n",
      "    try:\n",
      "        outputs, _, _ = rnn.bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
      "                                              dtype=tf.float32)\n",
      "    except Exception: # Old TensorFlow version only returns outputs not states\n",
      "        outputs = rnn.bidirectional_rnn(lstm_fw_cell, lstm_bw_cell, x,\n",
      "                                        dtype=tf.float32)\n",
      "\n",
      "    # Linear activation, using rnn inner loop last output\n",
      "    return tf.matmul(outputs[-1], weights['out']) + biases['out']\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "pred = BiRNN(x, weights, biases)\n",
      "\n",
      "# Define loss and optimizer\n",
      "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(pred, y))\n",
      "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)\n",
      "\n",
      "# Evaluate model\n",
      "correct_pred = tf.equal(tf.argmax(pred,1), tf.argmax(y,1))\n",
      "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32))\n",
      "\n",
      "# Initializing the variables\n",
      "init = tf.initialize_all_variables()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x1062b6e50>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x1062b6e50>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x1062b6b10>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stderr",
       "text": [
        "WARNING:tensorflow:<tensorflow.python.ops.rnn_cell.BasicLSTMCell object at 0x1062b6b10>: Using a concatenated state is slower and will soon be deprecated.  Use state_is_tuple=True.\n"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Strutified shuffle is used insted of simple shuffle in order to achieve sample balancing\n",
      "    # or equal number of examples in each of 10 classes.\n",
      "# Since there are different number of examples for each 10 classes in the MNIST data you may\n",
      "    # also use simple shuffle.\n",
      "\n",
      "def stratified_shuffle(labels, num_classes):\n",
      "    ix = np.argsort(labels).reshape((num_classes,-1))\n",
      "    for i in range(len(ix)):\n",
      "        np.random.shuffle(ix[i])\n",
      "    return ix.T.reshape((-1))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Training\n",
      "epochs_completed = 0\n",
      "index_in_epoch = 0\n",
      "num_examples = train_images.shape[0]\n",
      "\n",
      "# visualisation variables\n",
      "train_accuracies = []\n",
      "validation_accuracies = []\n",
      "x_range = []\n",
      "\n",
      "# serve data by batches\n",
      "def next_batch(batch_size):\n",
      "    \n",
      "    global train_images\n",
      "    global train_labels\n",
      "    global train_labels_flat\n",
      "    global index_in_epoch\n",
      "    global epochs_completed\n",
      "    \n",
      "    start = index_in_epoch\n",
      "    index_in_epoch += batch_size\n",
      "    \n",
      "    # when all trainig data have been already used, it is reorder randomly    \n",
      "    if index_in_epoch > num_examples:\n",
      "        # finished epoch\n",
      "        epochs_completed += 1\n",
      "        # shuffle the data\n",
      "        perm = np.arange(num_examples)\n",
      "        np.random.shuffle(perm)\n",
      "        #perm = stratified_shuffle(train_labels_flat, 10)\n",
      "        train_images = train_images[perm]\n",
      "        train_labels = train_labels[perm]\n",
      "        train_labels_flat = train_labels_flat[perm]\n",
      "        # start next epoch\n",
      "        start = 0\n",
      "        index_in_epoch = batch_size\n",
      "        assert batch_size <= num_examples\n",
      "    end = index_in_epoch\n",
      "    return train_images[start:end], train_labels[start:end]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 25
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Launch the graph\n",
      "saver = tf.train.Saver(max_to_keep=5)\n",
      "sess = tf.Session()\n",
      "sess.run(tf.initialize_all_variables())\n",
      "\n",
      "ckpt = tf.train.get_checkpoint_state('.')\n",
      "if ckpt and ckpt.model_checkpoint_path:\n",
      "    saver.restore(sess, ckpt.model_checkpoint_path)\n",
      "    print(\"Restored session from: %s\" % ckpt.model_checkpoint_path)\n",
      "else:\n",
      "    print(\"No checkpoint found.\")\n",
      "    \n",
      "start_step = global_step.eval(sess)\n",
      "for i in range(start_step, min(start_step + ITERATIONS_PER_RUN, TRAINING_ITERATIONS)):\n",
      "    sess.run(init)\n",
      "    step = 1\n",
      "    # Keep training until reach max iterations\n",
      "    while step * batch_size < training_iters:\n",
      "        batch_x, batch_y = next_batch(batch_size)\n",
      "        # Reshape data to get 28 seq of 28 elements\n",
      "        batch_x = batch_x.reshape((batch_size, n_steps, n_input))\n",
      "        # Run optimization op (backprop)\n",
      "        sess.run(optimizer, feed_dict={x: batch_x, y: batch_y})\n",
      "        if step % display_step == 0:\n",
      "            # Calculate batch accuracy\n",
      "            acc = sess.run(accuracy, feed_dict={x: batch_x, y: batch_y})\n",
      "            # Calculate batch loss\n",
      "            loss = sess.run(cost, feed_dict={x: batch_x, y: batch_y})\n",
      "            print(\"Iter \" + str(step*batch_size) + \", Minibatch Loss= \" + \\\n",
      "                  \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
      "                  \"{:.5f}\".format(acc))\n",
      "        step += 1\n",
      "    print(\"Optimization Finished!\")\n",
      "\n",
      "    test_len = 128\n",
      "    test_data =  validation_images.reshape((-1, n_steps, n_input))\n",
      "    test_label = validation_labels\n",
      "    print(\"Testing Accuracy:\", \\\n",
      "        sess.run(accuracy, feed_dict={x: test_data, y: test_label}))\n",
      "    saver.save(sess, 'model', global_step=i+1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Iter 1280, Minibatch Loss= 1.755664, Training Accuracy= 0.42969\n",
        "Iter 2560, Minibatch Loss= 1.212868, Training Accuracy= 0.62500"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 3840, Minibatch Loss= 0.904883, Training Accuracy= 0.68750"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 5120, Minibatch Loss= 0.811659, Training Accuracy= 0.73438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 6400, Minibatch Loss= 0.635554, Training Accuracy= 0.78125"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 7680, Minibatch Loss= 0.610600, Training Accuracy= 0.81250"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 8960, Minibatch Loss= 0.628577, Training Accuracy= 0.82812"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 10240, Minibatch Loss= 0.525954, Training Accuracy= 0.83594"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 11520, Minibatch Loss= 0.320729, Training Accuracy= 0.89844"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 12800, Minibatch Loss= 0.457968, Training Accuracy= 0.83594"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 14080, Minibatch Loss= 0.287802, Training Accuracy= 0.89062"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 15360, Minibatch Loss= 0.270891, Training Accuracy= 0.93750"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 16640, Minibatch Loss= 0.316820, Training Accuracy= 0.89844"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 17920, Minibatch Loss= 0.298229, Training Accuracy= 0.90625"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 19200, Minibatch Loss= 0.327001, Training Accuracy= 0.85938"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 20480, Minibatch Loss= 0.300310, Training Accuracy= 0.92188"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 21760, Minibatch Loss= 0.288746, Training Accuracy= 0.91406"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 23040, Minibatch Loss= 0.251030, Training Accuracy= 0.94531"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 24320, Minibatch Loss= 0.188075, Training Accuracy= 0.92969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 25600, Minibatch Loss= 0.212189, Training Accuracy= 0.92969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 26880, Minibatch Loss= 0.191988, Training Accuracy= 0.91406"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 28160, Minibatch Loss= 0.174374, Training Accuracy= 0.93750"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 29440, Minibatch Loss= 0.231610, Training Accuracy= 0.91406"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 30720, Minibatch Loss= 0.216877, Training Accuracy= 0.92188"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 32000, Minibatch Loss= 0.191306, Training Accuracy= 0.92969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 33280, Minibatch Loss= 0.219689, Training Accuracy= 0.92969"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 34560, Minibatch Loss= 0.173724, Training Accuracy= 0.94531"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 35840, Minibatch Loss= 0.102239, Training Accuracy= 0.96875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 37120, Minibatch Loss= 0.109119, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 38400, Minibatch Loss= 0.109292, Training Accuracy= 0.98438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 39680, Minibatch Loss= 0.306919, Training Accuracy= 0.90625"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 40960, Minibatch Loss= 0.203778, Training Accuracy= 0.92188"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 42240, Minibatch Loss= 0.284107, Training Accuracy= 0.89844"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 43520, Minibatch Loss= 0.138126, Training Accuracy= 0.97656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 44800, Minibatch Loss= 0.114046, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 46080, Minibatch Loss= 0.071983, Training Accuracy= 0.98438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 47360, Minibatch Loss= 0.103043, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 48640, Minibatch Loss= 0.144249, Training Accuracy= 0.95312"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 49920, Minibatch Loss= 0.139357, Training Accuracy= 0.95312"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 51200, Minibatch Loss= 0.133279, Training Accuracy= 0.96875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 52480, Minibatch Loss= 0.121659, Training Accuracy= 0.95312"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 53760, Minibatch Loss= 0.134236, Training Accuracy= 0.94531"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 55040, Minibatch Loss= 0.114976, Training Accuracy= 0.94531"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 56320, Minibatch Loss= 0.079626, Training Accuracy= 0.96875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 57600, Minibatch Loss= 0.100246, Training Accuracy= 0.96875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 58880, Minibatch Loss= 0.122625, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 60160, Minibatch Loss= 0.118390, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 61440, Minibatch Loss= 0.185835, Training Accuracy= 0.94531"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 62720, Minibatch Loss= 0.106119, Training Accuracy= 0.95312"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 64000, Minibatch Loss= 0.115121, Training Accuracy= 0.97656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 65280, Minibatch Loss= 0.115135, Training Accuracy= 0.95312"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 66560, Minibatch Loss= 0.117334, Training Accuracy= 0.97656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 67840, Minibatch Loss= 0.126765, Training Accuracy= 0.97656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 69120, Minibatch Loss= 0.138394, Training Accuracy= 0.95312"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 70400, Minibatch Loss= 0.071930, Training Accuracy= 0.98438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 71680, Minibatch Loss= 0.078006, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 72960, Minibatch Loss= 0.122468, Training Accuracy= 0.95312"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 74240, Minibatch Loss= 0.109707, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 75520, Minibatch Loss= 0.074332, Training Accuracy= 0.97656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 76800, Minibatch Loss= 0.100400, Training Accuracy= 0.97656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 78080, Minibatch Loss= 0.076505, Training Accuracy= 0.98438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 79360, Minibatch Loss= 0.146538, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 80640, Minibatch Loss= 0.142548, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 81920, Minibatch Loss= 0.033582, Training Accuracy= 0.99219"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 83200, Minibatch Loss= 0.075734, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 84480, Minibatch Loss= 0.100758, Training Accuracy= 0.96094"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 85760, Minibatch Loss= 0.054176, Training Accuracy= 0.98438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 87040, Minibatch Loss= 0.082799, Training Accuracy= 0.97656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 88320, Minibatch Loss= 0.115938, Training Accuracy= 0.98438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 89600, Minibatch Loss= 0.101315, Training Accuracy= 0.97656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 90880, Minibatch Loss= 0.077859, Training Accuracy= 0.96875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 92160, Minibatch Loss= 0.079088, Training Accuracy= 0.97656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 93440, Minibatch Loss= 0.082847, Training Accuracy= 0.97656"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 94720, Minibatch Loss= 0.075818, Training Accuracy= 0.96875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 96000, Minibatch Loss= 0.052176, Training Accuracy= 0.98438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 97280, Minibatch Loss= 0.071600, Training Accuracy= 0.96875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 98560, Minibatch Loss= 0.078695, Training Accuracy= 0.96875"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Iter 99840, Minibatch Loss= 0.095374, Training Accuracy= 0.98438"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Optimization Finished!"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "('Testing Accuracy:', 0.984375)\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'i' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-26-d1a26b3e8377>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidation_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Testing Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m         \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_label\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m     \u001b[0msaver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'i' is not defined"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}